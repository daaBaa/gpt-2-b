{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2 Fine Tuning Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkraybill/gpt-2-b/blob/finetuning/GPT2-b-finetuning2-774M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHiwt3Ww7FF6",
        "colab_type": "text"
      },
      "source": [
        "To try out GPT-2, do this:\n",
        "\n",
        "- go to the \"Runtime\" menu and click \"Change runtime type\" and make sure this is a Python 3 notebook, running with GPU hardware acceleration.\n",
        "- use the \"Files\" section to the left to upload a text file called \"train.txt\" which contains all the text you want to train on, and  a text file called \"val.txt\" which contains all the text you want to validate on.\n",
        "- run the steps below in order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE_fFgQ8a_Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etM-i8RwbcTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "dc24f025-b69d-4b82-c55f-8eb3c63d4410"
      },
      "source": [
        "!git clone https://github.com/jkraybill/gpt-2-b.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2-b'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Counting objects: 100% (301/301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 301 (delta 160), reused 301 (delta 160), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (301/301), 4.40 MiB | 3.94 MiB/s, done.\n",
            "Resolving deltas: 100% (160/160), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVTyGrhsbdep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8e64fcb-f391-4189-e7f7-7534aac2e4fa"
      },
      "source": [
        "cd gpt-2-b"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2-b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azu6KCOHbhIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5611fa2a-45ab-4161-ccbc-c4f70b1ba6c7"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: toposort==1.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.5)\n",
            "Requirement already satisfied: tensor2tensor in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.11.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (1.2.0.dev201909050105)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (0.10.11)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (2.8.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (1.7.11)\n",
            "Requirement already satisfied: gevent in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (1.16.5)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (0.98)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: mesh-tensorflow in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (0.0.5)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (19.9.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (4.1.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensor2tensor->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (0.14.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (5.4.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (2.2.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (1.11.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (19.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->tensor2tensor->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->tensor2tensor->-r requirements.txt (line 6)) (1.4.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor->-r requirements.txt (line 6)) (0.11.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor->-r requirements.txt (line 6)) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent->tensor2tensor->-r requirements.txt (line 6)) (0.4.15)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->tensor2tensor->-r requirements.txt (line 6)) (0.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->tensor2tensor->-r requirements.txt (line 6)) (4.4.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor->-r requirements.txt (line 6)) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor->-r requirements.txt (line 6)) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor->-r requirements.txt (line 6)) (0.15.6)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor->-r requirements.txt (line 6)) (0.4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor->-r requirements.txt (line 6)) (0.2.6)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor->-r requirements.txt (line 6)) (4.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tfds-nightly->tensor2tensor->-r requirements.txt (line 6)) (41.2.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client->tensor2tensor->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->tensor2tensor->-r requirements.txt (line 6)) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecmuIWxFgFBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "5291b7e6-ed69-4b55-a4b6-e046e04a323e"
      },
      "source": [
        "!python ./download_model.py 774M"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 725kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 37.4Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 621kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:59, 52.0Mit/s]                                 \n",
            "Fetching model.ckpt.index: 16.0kit [00:00, 6.95Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 1.38Mit [00:00, 36.1Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 28.0Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OhJ6ka_DD94",
        "colab_type": "text"
      },
      "source": [
        "The below step encodes your corpus into \"NPZ\" tokenized format for GPT-2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHsNeMNenxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "60eb7b19-eb88-4ef0-d12d-5e14d9626a54"
      },
      "source": [
        "!PYTHONPATH=src ./encode.py ../corpus-j2-train.txt train.txt.npz --model_name 774M\n",
        "!PYTHONPATH=src ./encode.py ../corpus-j2-val.txt val.txt.npz --model_name 774M"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading files\n",
            "100% 1/1 [00:38<00:00, 38.42s/it]\n",
            "Writing train.txt.npz\n",
            "Reading files\n",
            "100% 1/1 [00:06<00:00,  6.91s/it]\n",
            "Writing val.txt.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94oLzOq23474",
        "colab_type": "text"
      },
      "source": [
        "Training is below. It will auto-stop after val loss stops going down for a while, but you may want to interrupt it early.\n",
        "\n",
        "\"sample_every\" controls how often you get sample output from the trained model.\n",
        "\n",
        "\"save_every\" controls how often the model is saved.\n",
        "\n",
        "\"learning_rate\" is the AI learning rate. 0.00005 is the rate I've gotten the best results with, but I think most people are running with significantly higher rates, so you could try adjusting it.\n",
        "\n",
        "\"layers_to_train\" controls the number of layers to fine-tune. Reduce this number if you are getting Out of Memory type errors. I hit them in Colab at values larger than 336 for the 774M model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iErhMVWvkQy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "0762e776-ace8-4857-a0a5-f50f9819e6cd"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/jkraybill/gpt-2-b\n",
            "   f3284d2..f4bf21b  finetuning -> origin/finetuning\n",
            "Updating f3284d2..f4bf21b\n",
            "Fast-forward\n",
            " src/model.py | 3 \u001b[32m+\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 1 insertion(+), 2 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBJ6JoufBGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d75deb76-3464-4e99-8741-7effcd4be994"
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset train.txt.npz --val_dataset val.txt.npz --sample_every=1000 --save_every=25 --learning_rate=0.00005 --model_name=774M --layers_to_train=336 --optimizer=adafactor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2-b/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2-b/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:92: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:95: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-09-24 14:30:11.425453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2019-09-24 14:30:11.425713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27a3100 executing computations on platform Host. Devices:\n",
            "2019-09-24 14:30:11.425750: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-24 14:30:11.427746: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-24 14:30:11.502314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-24 14:30:11.503132: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27a32c0 executing computations on platform CUDA. Devices:\n",
            "2019-09-24 14:30:11.503166: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-24 14:30:11.503365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-24 14:30:11.504052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-24 14:30:11.504415: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-24 14:30:11.506001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-24 14:30:11.507260: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-24 14:30:11.507667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-24 14:30:11.509429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-24 14:30:11.510737: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-24 14:30:11.514811: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-24 14:30:11.514918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-24 14:30:11.515664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-24 14:30:11.516352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-24 14:30:11.516424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-24 14:30:11.517879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-24 14:30:11.517909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-24 14:30:11.517926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-24 14:30:11.518051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-24 14:30:11.518799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-24 14:30:11.519516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From ./train.py:96: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:109: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2-b/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2-b/src/sample.py:16: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2-b/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "Training 336 raw layers out of 436\n",
            "Training 336 net layers out of 436\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/adafactor.py:310: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/quantization.py:109: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From ./train.py:160: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:162: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:165: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "Loading checkpoint checkpoint/run1/model-136\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Loading dataset...\n",
            "100% 1/1 [00:00<00:00,  1.71it/s]\n",
            "100% 1/1 [00:00<00:00, 22.44it/s]\n",
            "dataset has 7113998 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUa2LujW82cy",
        "colab_type": "text"
      },
      "source": [
        "The step below simply copies your trained model to the model directory, so the output will use your training. If you don't do this, you will be running against the trained GPT-2 model without your finetuning training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNXhOM22fNHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/774M/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvtv6NUj5eXU",
        "colab_type": "text"
      },
      "source": [
        "Run the below step to generate unconditional samples (i.e. \"dream mode\").\n",
        "\n",
        "\"top_k\" controls how many options to consider per word (the larger, the more \"diverse\" the output - anything from 1 to about 50 usually works, I think values around 10 are pretty good).\n",
        "\n",
        "\"temperature\" controls the sampling of the words, from 0 to 1 where 1 is the most \"random\".\n",
        "\n",
        "\"length\" controls the number of words in each sample output.\n",
        "\n",
        "This command will run continuously until you turn it off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2csc2bZHfrXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/generate_unconditional_samples.py --top_k 20 --temperature 0.8 --length=300 --model_name=774M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwZl7JAn6d5y",
        "colab_type": "text"
      },
      "source": [
        "Run the command below to run in interactive / \"completion\" mode. You will get a prompt; just type in whatever prompt text you want, and the model will attempt to complete it \"nsamples\" times.\n",
        "\n",
        "\"top_k\", \"length\", and \"temperature\" work as specified above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugmKkFv__NI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 1 --length=30 --temperature 0.1 --nsamples 3 --model_name=774M"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}